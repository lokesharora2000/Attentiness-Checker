{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rscWRetJQf2e",
        "colab_type": "code",
        "outputId": "a0ddb4cd-4bf3-42e0-c08a-77239c97c242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DMaqGjgBkad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed40ff02-f8c4-41bc-d085-d859b96a5362"
      },
      "source": [
        "# set matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import packages\n",
        "from config import emotion_config as config\n",
        "from pipeline.preprocessing import ImageToArrayPreprocessor\n",
        "from pipeline.callbacks import EpochCheckpoint\n",
        "from pipeline.callbacks import TrainingMonitor\n",
        "from pipeline.io import HDF5DatasetGenerator\n",
        "from pipeline.nn.conv import EmotionVGGNet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "# construct the training and testing image generators for data\n",
        "# augmentation, then initialize the image preprocessor\n",
        "trainAug = ImageDataGenerator(rotation_range = 10, zoom_range = 0.1,\n",
        "    horizontal_flip = True, rescale = 1 / 255.0, fill_mode = \"nearest\")\n",
        "valAug = ImageDataGenerator(rescale = 1 / 255.0)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "# initialize the training and validation dataset generators\n",
        "\n",
        "trainGen = HDF5DatasetGenerator(config.TRAIN_HDF5, config.BATCH_SIZE,\n",
        "    aug = trainAug, preprocessors = [iap], classes = config.NUM_CLASSES)\n",
        "valGen = HDF5DatasetGenerator(config.VAL_HDF5, config.BATCH_SIZE,\n",
        "    aug = valAug, preprocessors = [iap], classes = config.NUM_CLASSES)\n",
        "\n",
        "# if there is no specific model checkpoint supplied, then initialize\n",
        "# the network and compile the model\n",
        "#if args[\"model\"] is None:\n",
        "print(\"compiling model...\")\n",
        "model = EmotionVGGNet.build(width = 48, height = 48, depth = 1,\n",
        "    classes = config.NUM_CLASSES)\n",
        "# opt = SGD(lr = 1e-2, momentum = 0.9, nesterov = True)\n",
        "opt = Adam(lr = 1e-3)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = opt,\n",
        "    metrics = [\"accuracy\"])\n",
        "\n",
        "## otherwise, load the checkpoint from disk\n",
        "#else:\n",
        "#    print(\"[INFO] loding {}...\".format(args[\"model\"]))\n",
        "#    model = load_model(args[\"model\"])\n",
        "\n",
        "    # update the learning rate\n",
        "# print(\"[INFO] old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
        "# K.set_value(model.optimizer.lr, 1e-5)\n",
        "# print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
        "\n",
        "# construct the set of callbacks\n",
        "figPath = os.path.sep.join([config.OUTPUT_PATH, \"vggnet_emotion_1.png\"])\n",
        "jsonPath = os.path.sep.join([config.OUTPUT_PATH, \"vggnet_emotion_1.json\"])\n",
        "\n",
        "callbacks = [\n",
        "    EpochCheckpoint(\"checkpoints\", every = 5, #startAt = args[\"start_epoch\"]\n",
        "                    ),TrainingMonitor(figPath, jsonPath = jsonPath) \n",
        "                    #startAt = args[\"start_epoch\"]och\"]                    \n",
        "]\n",
        "\n",
        "# train network\n",
        "history=model.fit_generator(\n",
        "    trainGen.generator(),\n",
        "    steps_per_epoch = trainGen.numImages // config.BATCH_SIZE,\n",
        "    validation_data = valGen.generator(),\n",
        "    validation_steps = valGen.numImages // config.BATCH_SIZE,\n",
        "    epochs = 60,\n",
        "    max_queue_size = config.BATCH_SIZE * 2,\n",
        "    callbacks = callbacks,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "# close the dataset\n",
        "\n",
        "trainGen.close()\n",
        "valGen.close()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pipeline/io/hdf5datasetgenerator.py:20: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  self.db = h5py.File(dbPath)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "compiling model...\n",
            "Epoch 1/60\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 3.3056 - acc: 0.2329 - val_loss: 2.6449 - val_acc: 0.3583\n",
            "Epoch 2/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 2.7127 - acc: 0.3337 - val_loss: 2.4364 - val_acc: 0.4013\n",
            "Epoch 3/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 2.3908 - acc: 0.4075 - val_loss: 2.1310 - val_acc: 0.4912\n",
            "Epoch 4/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 2.1526 - acc: 0.4543 - val_loss: 1.9354 - val_acc: 0.5267\n",
            "Epoch 5/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.9698 - acc: 0.4892 - val_loss: 1.7875 - val_acc: 0.5397\n",
            "Epoch 6/60\n",
            "224/224 [==============================] - 12s 52ms/step - loss: 1.8190 - acc: 0.5137 - val_loss: 1.6835 - val_acc: 0.5481\n",
            "Epoch 7/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.7101 - acc: 0.5261 - val_loss: 1.6018 - val_acc: 0.5545\n",
            "Epoch 8/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.6158 - acc: 0.5433 - val_loss: 1.4839 - val_acc: 0.5727\n",
            "Epoch 9/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.5440 - acc: 0.5527 - val_loss: 1.4500 - val_acc: 0.5764\n",
            "Epoch 10/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.4943 - acc: 0.5645 - val_loss: 1.3952 - val_acc: 0.6004\n",
            "Epoch 11/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.4552 - acc: 0.5729 - val_loss: 1.3856 - val_acc: 0.5822\n",
            "Epoch 12/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.4284 - acc: 0.5800 - val_loss: 1.4085 - val_acc: 0.5776\n",
            "Epoch 13/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.4100 - acc: 0.5839 - val_loss: 1.3722 - val_acc: 0.5871\n",
            "Epoch 14/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3861 - acc: 0.5921 - val_loss: 1.4144 - val_acc: 0.5808\n",
            "Epoch 15/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3674 - acc: 0.6007 - val_loss: 1.4697 - val_acc: 0.5504\n",
            "Epoch 16/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.3657 - acc: 0.6001 - val_loss: 1.3705 - val_acc: 0.5891\n",
            "Epoch 17/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.3548 - acc: 0.6052 - val_loss: 1.3818 - val_acc: 0.5909\n",
            "Epoch 18/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3552 - acc: 0.6069 - val_loss: 1.3561 - val_acc: 0.6044\n",
            "Epoch 19/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.3464 - acc: 0.6151 - val_loss: 1.3628 - val_acc: 0.6021\n",
            "Epoch 20/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.3423 - acc: 0.6169 - val_loss: 1.2985 - val_acc: 0.6215\n",
            "Epoch 21/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3404 - acc: 0.6177 - val_loss: 1.2989 - val_acc: 0.6160\n",
            "Epoch 22/60\n",
            "224/224 [==============================] - 19s 83ms/step - loss: 1.3311 - acc: 0.6216 - val_loss: 1.3231 - val_acc: 0.6120\n",
            "Epoch 23/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.3306 - acc: 0.6168 - val_loss: 1.3028 - val_acc: 0.6111\n",
            "Epoch 24/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3200 - acc: 0.6253 - val_loss: 1.3140 - val_acc: 0.6195\n",
            "Epoch 25/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3168 - acc: 0.6255 - val_loss: 1.2833 - val_acc: 0.6264\n",
            "Epoch 26/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3147 - acc: 0.6286 - val_loss: 1.3218 - val_acc: 0.6180\n",
            "Epoch 27/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.3127 - acc: 0.6306 - val_loss: 1.3438 - val_acc: 0.6123\n",
            "Epoch 28/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.3058 - acc: 0.6331 - val_loss: 1.2712 - val_acc: 0.6319\n",
            "Epoch 29/60\n",
            "224/224 [==============================] - 17s 78ms/step - loss: 1.3079 - acc: 0.6309 - val_loss: 1.2995 - val_acc: 0.6290\n",
            "Epoch 30/60\n",
            "224/224 [==============================] - 17s 78ms/step - loss: 1.3027 - acc: 0.6371 - val_loss: 1.3006 - val_acc: 0.6228\n",
            "Epoch 31/60\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2977 - acc: 0.6393 - val_loss: 1.2811 - val_acc: 0.6316\n",
            "Epoch 32/60\n",
            "151/224 [===================>..........] - ETA: 6s - loss: 1.2954 - acc: 0.6372"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/pipeline/io/hdf5datasetgenerator.py:20: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  self.db = h5py.File(dbPath)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "compiling model...\n",
            "Epoch 1/60\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 3.3056 - acc: 0.2329 - val_loss: 2.6449 - val_acc: 0.3583\n",
            "Epoch 2/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 2.7127 - acc: 0.3337 - val_loss: 2.4364 - val_acc: 0.4013\n",
            "Epoch 3/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 2.3908 - acc: 0.4075 - val_loss: 2.1310 - val_acc: 0.4912\n",
            "Epoch 4/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 2.1526 - acc: 0.4543 - val_loss: 1.9354 - val_acc: 0.5267\n",
            "Epoch 5/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.9698 - acc: 0.4892 - val_loss: 1.7875 - val_acc: 0.5397\n",
            "Epoch 6/60\n",
            "224/224 [==============================] - 12s 52ms/step - loss: 1.8190 - acc: 0.5137 - val_loss: 1.6835 - val_acc: 0.5481\n",
            "Epoch 7/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.7101 - acc: 0.5261 - val_loss: 1.6018 - val_acc: 0.5545\n",
            "Epoch 8/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.6158 - acc: 0.5433 - val_loss: 1.4839 - val_acc: 0.5727\n",
            "Epoch 9/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.5440 - acc: 0.5527 - val_loss: 1.4500 - val_acc: 0.5764\n",
            "Epoch 10/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.4943 - acc: 0.5645 - val_loss: 1.3952 - val_acc: 0.6004\n",
            "Epoch 11/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.4552 - acc: 0.5729 - val_loss: 1.3856 - val_acc: 0.5822\n",
            "Epoch 12/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.4284 - acc: 0.5800 - val_loss: 1.4085 - val_acc: 0.5776\n",
            "Epoch 13/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.4100 - acc: 0.5839 - val_loss: 1.3722 - val_acc: 0.5871\n",
            "Epoch 14/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3861 - acc: 0.5921 - val_loss: 1.4144 - val_acc: 0.5808\n",
            "Epoch 15/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3674 - acc: 0.6007 - val_loss: 1.4697 - val_acc: 0.5504\n",
            "Epoch 16/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.3657 - acc: 0.6001 - val_loss: 1.3705 - val_acc: 0.5891\n",
            "Epoch 17/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.3548 - acc: 0.6052 - val_loss: 1.3818 - val_acc: 0.5909\n",
            "Epoch 18/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3552 - acc: 0.6069 - val_loss: 1.3561 - val_acc: 0.6044\n",
            "Epoch 19/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.3464 - acc: 0.6151 - val_loss: 1.3628 - val_acc: 0.6021\n",
            "Epoch 20/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.3423 - acc: 0.6169 - val_loss: 1.2985 - val_acc: 0.6215\n",
            "Epoch 21/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3404 - acc: 0.6177 - val_loss: 1.2989 - val_acc: 0.6160\n",
            "Epoch 22/60\n",
            "224/224 [==============================] - 19s 83ms/step - loss: 1.3311 - acc: 0.6216 - val_loss: 1.3231 - val_acc: 0.6120\n",
            "Epoch 23/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.3306 - acc: 0.6168 - val_loss: 1.3028 - val_acc: 0.6111\n",
            "Epoch 24/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3200 - acc: 0.6253 - val_loss: 1.3140 - val_acc: 0.6195\n",
            "Epoch 25/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3168 - acc: 0.6255 - val_loss: 1.2833 - val_acc: 0.6264\n",
            "Epoch 26/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.3147 - acc: 0.6286 - val_loss: 1.3218 - val_acc: 0.6180\n",
            "Epoch 27/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.3127 - acc: 0.6306 - val_loss: 1.3438 - val_acc: 0.6123\n",
            "Epoch 28/60\n",
            "224/224 [==============================] - 18s 80ms/step - loss: 1.3058 - acc: 0.6331 - val_loss: 1.2712 - val_acc: 0.6319\n",
            "Epoch 29/60\n",
            "224/224 [==============================] - 17s 78ms/step - loss: 1.3079 - acc: 0.6309 - val_loss: 1.2995 - val_acc: 0.6290\n",
            "Epoch 30/60\n",
            "224/224 [==============================] - 17s 78ms/step - loss: 1.3027 - acc: 0.6371 - val_loss: 1.3006 - val_acc: 0.6228\n",
            "Epoch 31/60\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2977 - acc: 0.6393 - val_loss: 1.2811 - val_acc: 0.6316\n",
            "Epoch 32/60\n",
            "224/224 [==============================] - 21s 93ms/step - loss: 1.2940 - acc: 0.6394 - val_loss: 1.3062 - val_acc: 0.6189\n",
            "224/224 [==============================] - 21s 93ms/step - loss: 1.2940 - acc: 0.6394 - val_loss: 1.3062 - val_acc: 0.6189\n",
            "Epoch 33/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.3959 - acc: 0.6328Epoch 33/60\n",
            "224/224 [==============================] - 19s 83ms/step - loss: 1.2898 - acc: 0.6390 - val_loss: 1.2805 - val_acc: 0.6264\n",
            "224/224 [==============================] - 19s 83ms/step - loss: 1.2898 - acc: 0.6390 - val_loss: 1.2805 - val_acc: 0.6264\n",
            "Epoch 34/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.3981 - acc: 0.6016Epoch 34/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2890 - acc: 0.6390 - val_loss: 1.2639 - val_acc: 0.6354\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2890 - acc: 0.6390 - val_loss: 1.2639 - val_acc: 0.6354\n",
            "Epoch 35/60\n",
            "  1/224 [..............................] - ETA: 9s - loss: 1.3269 - acc: 0.6094Epoch 35/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2890 - acc: 0.6380 - val_loss: 1.2511 - val_acc: 0.6440\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2890 - acc: 0.6380 - val_loss: 1.2511 - val_acc: 0.6440\n",
            "Epoch 36/60\n",
            "  1/224 [..............................] - ETA: 8s - loss: 1.0946 - acc: 0.7578Epoch 36/60\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2851 - acc: 0.6444 - val_loss: 1.2690 - val_acc: 0.6368\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2851 - acc: 0.6444 - val_loss: 1.2690 - val_acc: 0.6368\n",
            "Epoch 37/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.3333 - acc: 0.6328Epoch 37/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2836 - acc: 0.6412 - val_loss: 1.2876 - val_acc: 0.6209\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2836 - acc: 0.6412 - val_loss: 1.2876 - val_acc: 0.6209\n",
            "Epoch 38/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.1383 - acc: 0.7500Epoch 38/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2813 - acc: 0.6444 - val_loss: 1.3547 - val_acc: 0.6120\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2813 - acc: 0.6444 - val_loss: 1.3547 - val_acc: 0.6120\n",
            "Epoch 39/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.3041 - acc: 0.6484Epoch 39/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2784 - acc: 0.6467 - val_loss: 1.2793 - val_acc: 0.6307\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2784 - acc: 0.6467 - val_loss: 1.2793 - val_acc: 0.6307\n",
            "Epoch 40/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.2645 - acc: 0.6484Epoch 40/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2785 - acc: 0.6462 - val_loss: 1.2705 - val_acc: 0.6383\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2785 - acc: 0.6462 - val_loss: 1.2705 - val_acc: 0.6383\n",
            "Epoch 41/60\n",
            "  1/224 [..............................] - ETA: 9s - loss: 1.2290 - acc: 0.6875Epoch 41/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2734 - acc: 0.6492 - val_loss: 1.3333 - val_acc: 0.6209\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2734 - acc: 0.6492 - val_loss: 1.3333 - val_acc: 0.6209\n",
            "Epoch 42/60\n",
            "  1/224 [..............................] - ETA: 11s - loss: 1.2650 - acc: 0.6641Epoch 42/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2674 - acc: 0.6528 - val_loss: 1.3309 - val_acc: 0.6097\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2674 - acc: 0.6528 - val_loss: 1.3309 - val_acc: 0.6097\n",
            "Epoch 43/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.2306 - acc: 0.6719Epoch 43/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2689 - acc: 0.6495 - val_loss: 1.4548 - val_acc: 0.5753\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2689 - acc: 0.6495 - val_loss: 1.4548 - val_acc: 0.5753\n",
            "Epoch 44/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.3333 - acc: 0.5859Epoch 44/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2664 - acc: 0.6495 - val_loss: 1.2865 - val_acc: 0.6354\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2664 - acc: 0.6495 - val_loss: 1.2865 - val_acc: 0.6354\n",
            "Epoch 45/60\n",
            "  1/224 [..............................] - ETA: 9s - loss: 1.2806 - acc: 0.6172Epoch 45/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2627 - acc: 0.6464 - val_loss: 1.3439 - val_acc: 0.6056\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2627 - acc: 0.6464 - val_loss: 1.3439 - val_acc: 0.6056\n",
            "Epoch 46/60\n",
            "  1/224 [..............................] - ETA: 8s - loss: 1.0878 - acc: 0.7188Epoch 46/60\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2592 - acc: 0.6490 - val_loss: 1.3071 - val_acc: 0.6195\n",
            "224/224 [==============================] - 18s 81ms/step - loss: 1.2592 - acc: 0.6490 - val_loss: 1.3071 - val_acc: 0.6195\n",
            "Epoch 47/60\n",
            "  1/224 [..............................] - ETA: 9s - loss: 1.2158 - acc: 0.7031Epoch 47/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2632 - acc: 0.6518 - val_loss: 1.3137 - val_acc: 0.6276\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2632 - acc: 0.6518 - val_loss: 1.3137 - val_acc: 0.6276\n",
            "Epoch 48/60\n",
            "  1/224 [..............................] - ETA: 8s - loss: 1.1918 - acc: 0.6719Epoch 48/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2518 - acc: 0.6511 - val_loss: 1.2711 - val_acc: 0.6322\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2518 - acc: 0.6511 - val_loss: 1.2711 - val_acc: 0.6322\n",
            "Epoch 49/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.1425 - acc: 0.7266Epoch 49/60\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2484 - acc: 0.6544 - val_loss: 1.2656 - val_acc: 0.6351\n",
            "224/224 [==============================] - 18s 82ms/step - loss: 1.2484 - acc: 0.6544 - val_loss: 1.2656 - val_acc: 0.6351\n",
            "Epoch 50/60\n",
            "  1/224 [..............................] - ETA: 12s - loss: 1.1577 - acc: 0.7031Epoch 50/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2540 - acc: 0.6538 - val_loss: 1.2267 - val_acc: 0.6565\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2540 - acc: 0.6538 - val_loss: 1.2267 - val_acc: 0.6565\n",
            "Epoch 51/60\n",
            "  1/224 [..............................] - ETA: 15s - loss: 1.1411 - acc: 0.6719Epoch 51/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2465 - acc: 0.6564 - val_loss: 1.2636 - val_acc: 0.6452\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2465 - acc: 0.6564 - val_loss: 1.2636 - val_acc: 0.6452\n",
            "Epoch 52/60\n",
            "  1/224 [..............................] - ETA: 11s - loss: 1.2593 - acc: 0.6406Epoch 52/60\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2443 - acc: 0.6588 - val_loss: 1.2392 - val_acc: 0.6504\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2443 - acc: 0.6588 - val_loss: 1.2392 - val_acc: 0.6504\n",
            "Epoch 53/60\n",
            "  1/224 [..............................] - ETA: 8s - loss: 1.3859 - acc: 0.6328Epoch 53/60\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2446 - acc: 0.6570 - val_loss: 1.2964 - val_acc: 0.6250\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2446 - acc: 0.6570 - val_loss: 1.2964 - val_acc: 0.6250\n",
            "Epoch 54/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.2423 - acc: 0.6406Epoch 54/60\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2522 - acc: 0.6526 - val_loss: 1.2487 - val_acc: 0.6518\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2522 - acc: 0.6526 - val_loss: 1.2487 - val_acc: 0.6518\n",
            "Epoch 55/60\n",
            "  1/224 [..............................] - ETA: 11s - loss: 1.2532 - acc: 0.6797Epoch 55/60\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2451 - acc: 0.6571 - val_loss: 1.2501 - val_acc: 0.6437\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2451 - acc: 0.6571 - val_loss: 1.2501 - val_acc: 0.6437\n",
            "Epoch 56/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.1503 - acc: 0.7188Epoch 56/60\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2443 - acc: 0.6567 - val_loss: 1.2627 - val_acc: 0.6351\n",
            "224/224 [==============================] - 19s 84ms/step - loss: 1.2443 - acc: 0.6567 - val_loss: 1.2627 - val_acc: 0.6351\n",
            "Epoch 57/60\n",
            "  1/224 [..............................] - ETA: 8s - loss: 1.2606 - acc: 0.6328Epoch 57/60\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2478 - acc: 0.6557 - val_loss: 1.3211 - val_acc: 0.6218\n",
            "224/224 [==============================] - 19s 85ms/step - loss: 1.2478 - acc: 0.6557 - val_loss: 1.3211 - val_acc: 0.6218\n",
            "Epoch 58/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.1627 - acc: 0.7266Epoch 58/60\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2379 - acc: 0.6602 - val_loss: 1.2567 - val_acc: 0.6472\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2379 - acc: 0.6602 - val_loss: 1.2567 - val_acc: 0.6472\n",
            "Epoch 59/60\n",
            "  1/224 [..............................] - ETA: 10s - loss: 1.1510 - acc: 0.6719Epoch 59/60\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2340 - acc: 0.6612 - val_loss: 1.3092 - val_acc: 0.6175\n",
            "224/224 [==============================] - 19s 86ms/step - loss: 1.2340 - acc: 0.6612 - val_loss: 1.3092 - val_acc: 0.6175\n",
            "Epoch 60/60\n",
            "  1/224 [..............................] - ETA: 9s - loss: 1.2122 - acc: 0.6797Epoch 60/60\n",
            "224/224 [==============================] - 19s 87ms/step - loss: 1.2322 - acc: 0.6633 - val_loss: 1.2459 - val_acc: 0.6449\n",
            "224/224 [==============================] - 19s 87ms/step - loss: 1.2322 - acc: 0.6633 - val_loss: 1.2459 - val_acc: 0.6449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3icplZhnuNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDeUz_JvQbLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}